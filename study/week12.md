Week 12 (01/22 ~ 01/26)
===
>  ##### 주간 요약
>  

Day 53 (01/22)
---
오늘은 MF를 구현해 학습을 시키고, 결과를 분석해봤다.  
MF를 사용하니 2가지 특징이 있었다.  
첫째는 학습이 진행됨에 따라 AUC는 증가하는데, ACC는 변하지 않는다는 점이다.  
이때 ACC가 약 0.66 정도에서 고정되는데, 이 값은 전체 데이터의 평균 정답률이다.  
MF가 평균 정답률과의 차이를 추론하는 모델임을 생각하면 parameter의 가중치들이 크기가 작을 것이라 예상해 볼 수 있다.  
둘째 특징이 이를 뒷받침하는데, 모든 추론값이 0.66에 근사하게 나타난다는 점이다.  
즉, 모델은 추론값이 평균 정답률에서 크게 벗어나지 않도록 학습되고 있음을 의미한다.  
lr, batch size 등 hyper parameter의 영향일 수도 있겠으나, wandb의 sweep으로 튜닝을 어느 정도 해 봐도 같은 현상이 계속 나타났다.  
혹은 MF가 regression에 적합한 모델이라 0과 1로 분류되는 DKT dataset에 어울리지 않을 가능성도 있다.  
이 부분의 경우 implicit data를 예측하기 위한 logistic MF라는 것이 있길래 이걸 활용해보려고 계획 중이다.  
추론을 할 때 평균 정답률을 제외하고 두 embedding의 내적과 bias만을 사용하는 것도 고려해 볼 수 있겠다.  

그리고 ACC는 그대로지만 AUC가 늘어난다는 점은 달리 말해 추론값의 차이는 미세하지만 어찌 됐든 두 데이터를 구분해내고 있음을 의미하기도 한다.  
이에 대해 정리하다보니 모델을 앙상블 할 때 AUC를 고려하면 추론값을 가중합하는 것이 아니라 추론값의 크기에 따라 순위를 매기고 이를 가중합하는 식으로 활용해야 하지 않을까 싶기도 하다.  
내일 조원들과 토론해보고 멘토링 때도 여쭤봐야겠다.  

+ ##### 키워드: MF, Logistic MF
