Week 12 (01/22 ~ 01/26)
===
>  ##### 주간 요약
>  

Day 53 (01/22)
---
오늘은 MF를 구현해 학습을 시키고, 결과를 분석해봤다.  
MF를 사용하니 2가지 특징이 있었다.  
첫째는 학습이 진행됨에 따라 AUC는 증가하는데, ACC는 변하지 않는다는 점이다.  
이때 ACC가 약 0.66 정도에서 고정되는데, 이 값은 전체 데이터의 평균 정답률이다.  
MF가 평균 정답률과의 차이를 추론하는 모델임을 생각하면 parameter의 가중치들이 크기가 작을 것이라 예상해 볼 수 있다.  
둘째 특징이 이를 뒷받침하는데, 모든 추론값이 0.66에 근사하게 나타난다는 점이다.  
즉, 모델은 추론값이 평균 정답률에서 크게 벗어나지 않도록 학습되고 있음을 의미한다.  
lr, batch size 등 hyper parameter의 영향일 수도 있겠으나, wandb의 sweep으로 튜닝을 어느 정도 해 봐도 같은 현상이 계속 나타났다.  
혹은 MF가 regression에 적합한 모델이라 0과 1로 분류되는 DKT dataset에 어울리지 않을 가능성도 있다.  
이 부분의 경우 implicit data를 예측하기 위한 logistic MF라는 것이 있길래 이걸 활용해보려고 계획 중이다.  
추론을 할 때 평균 정답률을 제외하고 두 embedding의 내적과 bias만을 사용하는 것도 고려해 볼 수 있겠다.  

그리고 ACC는 그대로지만 AUC가 늘어난다는 점은 달리 말해 추론값의 차이는 미세하지만 어찌 됐든 두 데이터를 구분해내고 있음을 의미하기도 한다.  
이에 대해 정리하다보니 모델을 앙상블 할 때 AUC를 고려하면 추론값을 가중합하는 것이 아니라 추론값의 크기에 따라 순위를 매기고 이를 가중합하는 식으로 활용해야 하지 않을까 싶기도 하다.  
내일 조원들과 토론해보고 멘토링 때도 여쭤봐야겠다.  

+ ##### 키워드: MF, Logistic MF

Day 54 (01/23)
---
어제 구현한 MF와 logistic MF에 대해 wandb의 sweep으로 hyper parameter tuning을 해 봤는데, 성능이 그렇게 좋게 나오지 않았다.  
멘토님께서는 데이터 구조가 MF에 맞지 않거나 데이터 수가 모자라는 등의 원인이 있을 거라고 하셨다.  
또는 유저의 정보와 아이템의 정보를 embedding dimension으로 쪼개는 과정에서 정보가 많이 흩어져서 그럴 가능성도 있다고 하셨다.  
결론적으로 MF 계열은 크게 성능 개선의 여지가 없어보여서, 다른 방향으로 접근해보기로 했다.  

2번째로 시도한 것은 앙상블 방법의 변화이다.  
현재는 모델의 추론값을 가중합하는 방식으로 앙상블을 진행 중이었는데, AUC를 고려하면 각 추론값이 각 모델의 전체 추론값에서 차지하는 등수들을 합하는 방식이 어울리겠다고 생각했다.  
왜냐하면 어떤 모델은 0~1 사이로 넓게 추론을 하고, 다른 모델은 0.6 근처에서 좁게 추론을 한다면 두 모델의 AUC는 비슷해도 첫 모델의 영향력이 상대적으로 커지기 때문이다.  
가중치를 적절히 조절해주는 것도 가능하겠으나, 리더보드 제출 횟수가 제한되어있기에 가중치를 여러 번 바꿔가며 실험하기가 어렵기도 하다.  
실험 결과, 두 모델의 추론값을 단순 평균한 것과 비슷한 성능을 보였다.  
앙상블에 사용한 두 모델의 추론 범위가 크게 다르지 않아서 그런 것 같기도 하다. MF 계열의 모델은 추론 범위가 굉장히 좁은데, 이런 모델과 앙상블 할 때는 더 효과를 볼 수 있지 않을까 싶다.  

3번째로 시도한 것은 loss function의 대체이다.  
현재 BCELogitLoss를 사용 중인데, 이는 AUC를 직접적으로 높여주는 목적식이 아니다.  
그래서 다른 loss function을 찾다가 roc-star라는 것을 발견했다. [링크](https://github.com/iridiumblue/roc-star)  
실제 label이 0인 데이터의 추론 값이 1인 데이터의 추론 값보다 클 경우, 두 값의 차이를 이용해 loss를 계산하는 방식이다.  
다만 그대로 구현했을 때 loss는 줄어드는데 AUC는 오히려 떨어진다거나, gradient가 0으로 소실되는 등의 문제가 생겼다.  
실제로 사용하기 위해서는 조금 더 다듬어 볼 필요가 있을 듯하다.  

+ ##### 키워드: 앙상블, roc-star

Day 55 (01/24)
---
어젯밤에 loss function 구현에 성공했다.  
기존 코드가 우리 모델 구조와 안 맞는 부분이 있어서 관련된 논문에 적힌 수식을 읽고 직접 구현했더니 잘 작동했다.  
실제로 모델 성능도 좋아져서, AUC가 0.71 정도 나오던 모델이 0.74 정도까지 성능이 올라갔다.  

그리고 data augmentation도 수정을 했다.  
기존에 사용하던 sliding window 방식이 별 효과가 없어서 사실상 폐기되었는데, augmentation 방식을 변경하니 효과가 있었다.  
현재 사용하는 feature 중에 해당 user가 시험지를 몇 개째 풀고 있는지 나타내는 값이 있는데, 이 값이 바뀔 때마다 데이터를 잘라서 추가했다.  
이렇게 변경한 근거는 평균 정답률이 66%인 것에 비해 LB에서 확인하는 마지막 문제들의 정답률은 44% 정도로 차이가 나기 때문이다.  
그래서 data augmentation으로 늘어난 데이터들도 모두 각 시험지의 마지막 문제 정답 여부를 예측하도록 만들어줬다.  
데이터가 늘어나니 모델의 학습 속도가 많이 느려져서 실험을 많이 못 해 봤지만, 성능 향상이 있는 것으로 보인다.  

내일이 대회 마지막 날이라, 오늘까지 모델을 최대한 튜닝해서 제출해보고 내일은 그 모델들을 앙상블 해서 LB score를 올려보며 마무리하기로 했다.  

+ ##### 키워드: ROC loss function 구현, data augmentation 구현
