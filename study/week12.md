Week 12 (01/22 ~ 01/26)
===
>  ##### 주간 요약
>  MF, logistic MF 모델, AUC를 고려한 loss function, AUC를 고려한 앙상블 등을 구현했다.  
>  Data augmentation 코드를 수정하여 성능 향상을 이뤘다.  
>  DKT 프로젝트 대회를 7등으로 마무리했다.  

Day 53 (01/22)
---
오늘은 MF를 구현해 학습을 시키고, 결과를 분석해봤다.  
MF를 사용하니 2가지 특징이 있었다.  
첫째는 학습이 진행됨에 따라 AUC는 증가하는데, ACC는 변하지 않는다는 점이다.  
이때 ACC가 약 0.66 정도에서 고정되는데, 이 값은 전체 데이터의 평균 정답률이다.  
MF가 평균 정답률과의 차이를 추론하는 모델임을 생각하면 parameter의 가중치들이 크기가 작을 것이라 예상해 볼 수 있다.  
둘째 특징이 이를 뒷받침하는데, 모든 추론값이 0.66에 근사하게 나타난다는 점이다.  
즉, 모델은 추론값이 평균 정답률에서 크게 벗어나지 않도록 학습되고 있음을 의미한다.  
lr, batch size 등 hyper parameter의 영향일 수도 있겠으나, wandb의 sweep으로 튜닝을 어느 정도 해 봐도 같은 현상이 계속 나타났다.  
혹은 MF가 regression에 적합한 모델이라 0과 1로 분류되는 DKT dataset에 어울리지 않을 가능성도 있다.  
이 부분의 경우 implicit data를 예측하기 위한 logistic MF라는 것이 있길래 이걸 활용해보려고 계획 중이다.  
추론을 할 때 평균 정답률을 제외하고 두 embedding의 내적과 bias만을 사용하는 것도 고려해 볼 수 있겠다.  

그리고 ACC는 그대로지만 AUC가 늘어난다는 점은 달리 말해 추론값의 차이는 미세하지만 어찌 됐든 두 데이터를 구분해내고 있음을 의미하기도 한다.  
이에 대해 정리하다보니 모델을 앙상블 할 때 AUC를 고려하면 추론값을 가중합하는 것이 아니라 추론값의 크기에 따라 순위를 매기고 이를 가중합하는 식으로 활용해야 하지 않을까 싶기도 하다.  
내일 조원들과 토론해보고 멘토링 때도 여쭤봐야겠다.  

+ ##### 키워드: MF, Logistic MF

Day 54 (01/23)
---
어제 구현한 MF와 logistic MF에 대해 wandb의 sweep으로 hyper parameter tuning을 해 봤는데, 성능이 그렇게 좋게 나오지 않았다.  
멘토님께서는 데이터 구조가 MF에 맞지 않거나 데이터 수가 모자라는 등의 원인이 있을 거라고 하셨다.  
또는 유저의 정보와 아이템의 정보를 embedding dimension으로 쪼개는 과정에서 정보가 많이 흩어져서 그럴 가능성도 있다고 하셨다.  
결론적으로 MF 계열은 크게 성능 개선의 여지가 없어보여서, 다른 방향으로 접근해보기로 했다.  

2번째로 시도한 것은 앙상블 방법의 변화이다.  
현재는 모델의 추론값을 가중합하는 방식으로 앙상블을 진행 중이었는데, AUC를 고려하면 각 추론값이 각 모델의 전체 추론값에서 차지하는 등수들을 합하는 방식이 어울리겠다고 생각했다.  
왜냐하면 어떤 모델은 0~1 사이로 넓게 추론을 하고, 다른 모델은 0.6 근처에서 좁게 추론을 한다면 두 모델의 AUC는 비슷해도 첫 모델의 영향력이 상대적으로 커지기 때문이다.  
가중치를 적절히 조절해주는 것도 가능하겠으나, 리더보드 제출 횟수가 제한되어있기에 가중치를 여러 번 바꿔가며 실험하기가 어렵기도 하다.  
실험 결과, 두 모델의 추론값을 단순 평균한 것과 비슷한 성능을 보였다.  
앙상블에 사용한 두 모델의 추론 범위가 크게 다르지 않아서 그런 것 같기도 하다. MF 계열의 모델은 추론 범위가 굉장히 좁은데, 이런 모델과 앙상블 할 때는 더 효과를 볼 수 있지 않을까 싶다.  

3번째로 시도한 것은 loss function의 대체이다.  
현재 BCELogitLoss를 사용 중인데, 이는 AUC를 직접적으로 높여주는 목적식이 아니다.  
그래서 다른 loss function을 찾다가 roc-star라는 것을 발견했다. [링크](https://github.com/iridiumblue/roc-star)  
실제 label이 0인 데이터의 추론 값이 1인 데이터의 추론 값보다 클 경우, 두 값의 차이를 이용해 loss를 계산하는 방식이다.  
다만 그대로 구현했을 때 loss는 줄어드는데 AUC는 오히려 떨어진다거나, gradient가 0으로 소실되는 등의 문제가 생겼다.  
실제로 사용하기 위해서는 조금 더 다듬어 볼 필요가 있을 듯하다.  

+ ##### 키워드: 앙상블, roc-star

Day 55 (01/24)
---
어젯밤에 loss function 구현에 성공했다.  
기존 코드가 우리 모델 구조와 안 맞는 부분이 있어서 관련된 논문에 적힌 수식을 읽고 직접 구현했더니 잘 작동했다.  
실제로 모델 성능도 좋아져서, AUC가 0.71 정도 나오던 모델이 0.74 정도까지 성능이 올라갔다.  

그리고 data augmentation도 수정을 했다.  
기존에 사용하던 sliding window 방식이 별 효과가 없어서 사실상 폐기되었는데, augmentation 방식을 변경하니 효과가 있었다.  
현재 사용하는 feature 중에 해당 user가 시험지를 몇 개째 풀고 있는지 나타내는 값이 있는데, 이 값이 바뀔 때마다 데이터를 잘라서 추가했다.  
이렇게 변경한 근거는 평균 정답률이 66%인 것에 비해 LB에서 확인하는 마지막 문제들의 정답률은 44% 정도로 차이가 나기 때문이다.  
그래서 data augmentation으로 늘어난 데이터들도 모두 각 시험지의 마지막 문제 정답 여부를 예측하도록 만들어줬다.  
데이터가 늘어나니 모델의 학습 속도가 많이 느려져서 실험을 많이 못 해 봤지만, 성능 향상이 있는 것으로 보인다.  

내일이 대회 마지막 날이라, 오늘까지 모델을 최대한 튜닝해서 제출해보고 내일은 그 모델들을 앙상블 해서 LB score를 올려보며 마무리하기로 했다.  

+ ##### 키워드: ROC loss function 구현, data augmentation 구현

Day 56 (01/25)
---
마지막까지 모델 튜닝을 최대한 해 봤는데, CV score와 LB score의 차이가 생각보다 심해서 큰 소득은 없었다.  
그래도 몇 가지 모델 개선을 시도해서 valid score만 봤을 때 성과를 얻은 부분도 있다.  

우선 모델 학습 과정이 너무 오래 걸려서 원인을 찾아봤는데, 새로운 loss 계산식에서 모든 pair를 고려하다보니 시간복잡도가 너무 높아지는 게 문제였다.  
그래서 1000개 정도의 예측값을 sampling 한 후 그 값들의 pair를 기준으로 loss를 계산하도록 변경했다.  
loss 계산의 정확도를 약간 포기하고 속도를 크게 증가시키기 위한 전략이었는데, 예상대로 속도가 많이 빨라져서 효과가 있었다.  
다른 분도 학습 속도 관련해서 문제를 겪으셨는데, dataset에서 데이터를 넘겨받을 때 병목현상이 생기는 걸 확인 후 개선하셨다고 한다.  
num workers의 수를 늘리고, 원래 한 item을 전달할 때마다 전처리를 진행하던 것을 미리 전처리를 마친 후 결과값만 저장해두고 반환하는 식으로 변경하셨다고 한다.  
대신 이 경우 한 batch를 학습하는 시간은 줄어들지만, 모델이 학습을 시작하기 전의 overhead가 많이 커진다.  

그 외에 모델에서 사용하는 embedding의 initialization을 변경했더니 성능이 올라갔다.  
예전에 강의를 들으며 미션을 해결할 때 initialization이 성능에 영향을 준 경우가 기억나서 시도해봤는데, 왜 성능이 올라가는지는 잘 모르겠다.  
이 역시 hyper parameter 튜닝의 영역이 아닐까 생각 중이다.  

각자 모델 성능을 최대한 끌어올려본 후에는 앙상블을 몇 가지 시도해보며 리더보드 제출을 마무리했다.  
public score는 8등이었는데, private score가 공개되며 한 등수 올라 7등으로 마무리했다.  
LB score가 기대에 못 미쳐서 아쉽기도 했지만, 해 보고 싶었던 것들은 많이 시도해봐서 만족했다.  
그리고 지난 프로젝트 때도 느꼈지만, 실패를 겪어도 웃으면서 다시 시도할 수 있는 분위기가 중요하다고 생각한다.  
오늘 마지막 제출 횟수가 남았을 때 weighted sum 앙상블을 하기로 했는데, 가중치를 어떻게 줄지 고민하다가 numpy로 랜덤한 값을 추출해서 넣어줬다.  
논리적으로는 전혀 의미 없는 행동이지만, 다들 재밌다며 찬성해줘서 웃으면서 프로젝트를 마무리했다.  

+ ##### 키워드: Weight Initialization, DKT 대회 종료

Day 57 (01/26)
---
대회 1,2등 팀의 솔루션 발표를 들었다.  
여러 내용들이 있었는데 간단히 요약하자면 최대한 다양한 모델링을 연구하며 시도한 팀과 다양한 Feature Engineering을 시도한 팀이었다.  
모델링을 한 팀은 시도했다가 폐기한 모델만 15개가 되고, 다른 팀은 90개의 feature를 만들었다고 한다.  
두 팀 모두 EDA부터 모델링, 협업, 실험 관리까지 기본기들이 굉장히 탄탄한 느낌이었다.  

그래도 우리 조는 여러 창의적인 시도들을 많이 시도했다는 생각이 들었다.  
1위 조에서 실패했던 data augmentation을 우리 조는 방식을 바꿔서 성공하기도 했기에, 비록 결과는 7등이지만 몇 가지 솔루션을 공유해도 좋겠다는 생각이 들었다.  
그래서 대회 게시판에 성능 개선에 성공했던 방법들 위주로 솔루션을 공유했다.  
해당 글은 사이트에 로그인을 해야만 볼 수 있어서, 별도로 마크다운을 작성 후 링크를 남긴다.  

+ ##### 키워드: 대회 솔루션 공유
