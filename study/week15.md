Week 14 (02/13 ~ 02/16)
===
>  ##### 주간 요약
>  

Day 66 (02/13)
---
설날 연휴가 지나고 다시 캠프가 시작된 날이다.  
연휴동안 모델에 자꾸 미련이 남아서 CFM을 구현하고 다듬느라 제대로 쉬질 못한 느낌이다.  
그래서 그런지 간만의 캠프 활동이 꽤나 피곤했다.  
그래도 연휴동안 완성은 거의 한 상태고, 모델이 학습하는 시간이 오래 걸려서 학습을 기다리며 코드를 조금 가다듬는 정도의 작업만 했다.  

확실히 CFM이 기존 FM에 비해서 성능은 잘 나오는 것 같다.  
Multi-hot encoding에 유연하게 대응할 수 있다는 점에서도 이번 프로젝트와 어울리는 부분이 있다.  
다만 그럼에도 RecBole이라는 library의 성능을 뛰어넘기는 힘든 것 같다.  

남은 프로젝트 기간동안은 뭘 더 시도해볼지 고민을 해 봐야겠다.  
지금까지 베이스라인 구축, 모델링 등으로 작업량이 꽤나 많았어서 방전된 느낌도 드는데, 적당히 모델 실험을 돌리면서 아이디어 구상을 하는 시간을 가져야겠다.  

+ ###### CFM 구현, RecBole

Day 67 (02/14)
---
오늘은 그동안 구현해 둔 LCFM과 CFM을 돌려두고, RecBole에서 성능이 잘 나왔던 EASE 모델을 구현해봤다.  
논문을 봤는데 구조 자체가 워낙 간단해서 구현은 어렵지 않았다. 도중에 실수한 부분이 하나 있어서 성능이 제대로 안 나왔는데, 조원분이 리뷰를 통해 찾아주셔서 고쳤다.  
실제로 구현해서 돌려보니 RecBole에서 나오던 성능보다 더 잘 나왔다.  
valid split의 여부나 이미 본 영화를 masking 하는 등의 차이로 인한 결과인 것 같다.  

그리고 LCFM의 경우에는 layer가 깊어졌을 때 기울기 소실 문제가 발생하는 것 같다.  
loss가 자꾸 이상하게 나와서 debugging을 해 보니 모든 입력값에 대해 예측값이 비슷하게 출력되는 문제가 있었다.  
실제로 layer를 줄이니 이러한 문제가 없어졌다.  

기울기 소실이 문제라고 한다면 skip connection이나 batch norm 등을 활용할 수 있을 것 같은데, skip connection은 dimension이 계속 변하는 모델이라 적용이 어려울 듯하다.  
그래서 convolutional layer 사이에 batch norm을 끼워넣는 방안을 우선 고려 중이고, 내일은 leaky ReLU도 넣어서 테스트 해 볼 예정이다.  
다만 EASE 모델 성능이 워낙 좋아서 이걸 뛰어넘기는 힘들 듯하다.  
적당한 성능을 내서 앙상블에 활용하는 수준 정도를 목표로 해야겠다.  

+ ##### EASE 구현, 기울기 소실
