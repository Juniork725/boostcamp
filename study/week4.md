Week 3 (11/20 ~ 11/24)
===
>  ##### 주간 요약

Day 16 (11/27)
---
이번주부터 CV, NLP, RecSys로 나뉘어 도메인별 강의가 진행된다.  
내가 선택한 RecSys 도메인에서는 2주에 걸쳐 RecSys 기초와 지난주에 이은 DataViz. 후반부 강의가 진행될 예정이다.  

사실 RecSys는 CV와 NLP를 모두 활용한다는 말을 들어서 단순히 두 도메인을 적당히 반반 배울 거라 생각했다.  
그런데 강의를 들어보니 RecSys에서 특별히 다뤄지는 내용들이 있어서 신기했다.  
특히 RecSys는 실시간으로 빠른 추론을 해야 하는 경우가 많고, DL을 통한 성능 개선이 크지 않아 고전적인 ML을 활용하는 경우도 많다고 했다.  

그 중에서도 오늘은 단순히 인기도를 기반으로 한 추천 시스템, 추천 시스템의 평가 지표, 연관 규칙 분석, TF-IDF 등에 대해 배웠다.  
강의에서는 AP@K를 (Precision@i 들의 합)/m으로 계산했는데, 실제로는 Precision@i에 relevance_i를 곱해서 계산하는 것 같다.  
그 외에도 연관 규칙 분석을 설명할 때 n(X u Y)에서는 X, Y를 어떤 itemset으로 간주했다가, 이로부터 계산되는 P(X n Y)에서는 X, Y를 transaction에 itemset이 포함되는 사건으로 간주하는 혼용이 있었다.  
이런 경우들이 있다보니 전반적으로 강의를 이해하는 건 어렵지 않은데 중간중간 혼란스러운 부분들이 좀 있었다.  

그래도 큰 어려움 없이 목표치까지 공부를 마친 후 시간이 조금 남아서 지난주 심화 과제 1을 풀어봤다.  
조교님이 지난주 오피스 아워에 잘 설명해주신 덕에 과제를 쉽게 이해하며 풀 수 있었는데, 마지막에 예상치 못하게 error가 나타나서 골머리를 앓았다.  
정답 코드와 비교해도 크게 다른 부분이 없어서 머리를 싸맸는데, 알고 보니 굉장히 허무한 이유였다.  
image_embedding 이라는 class가 있는데, 내가 image_embedding 이라는 이름의 attribute를 선언하고 호출해서 문제가 된 것이었다.  
이름을 선정할 때 조금 더 주의를 기울여야겠다.  

그리고 마스터클래스에서는 AI의 성능 개선이 꼭 UX의 개선으로 이어지지는 않는다는 말이 인상깊었다.  
사실 이제까지 UX가 UI와 비슷한 의미인 줄 알았는데 User Experience의 약자라는 걸 오늘 알았다.  
실제 서비스에서 중요한 것은 AI의 성능보다도 UX이기에 다방면에서 이를 개선하기 위한 접근이 필요하다.  
이때 AARRR이라는 개념이 있는데, 유저가 서비스에 접근하고 사용하는 과정을 5단계로 분리한 것이다.  
이 AARRR의 각 단계마다 중요한 요소가 다르고, 이에 맞는 전략이 필요하다고 한다.  
나 역시 단순히 성능 좋은 AI를 만드는 것보다는 AI 서비스를 통해 사람들에게 이로운 가치를 창출하는 것이 목표이기에, 언젠가는 반드시 이에 대한 고민을 필요로 하는 날이 올 것이다.  
그 외에 인상 깊었던 내용으로는 영어의 중요성이 있었다.  
개발자에게 영어는 document를 읽을 정도면 충분하다는 의견도 있는 반면, 마스터님께서는 영어를 잘하는 것이 새로운 무대를 열어줄 수 있기에 중요하다고 하셨다.  

>  오늘의 질문 횟수: 2  
>  오늘의 답변 횟수: 2

+ ##### 키워드: RecSys Metrics, 연관 규칙 분석, TF-IDF, UX

Day 17 (11/28)
---
오늘은 Git 사용법에 대한 특강이 있었다. 실시간으로 실습해보며 Visual Studio Code에서 git을 어떻게 다루는지 배웠다.  
Git 자체는 이전에도 몇번 공부한 적이 있기에 add, commit, branch 등 기초 개념들에는 익숙했다.  
하지만 VSC로 다뤄본 적이 없어서 단축키나 extension 등 좀 더 실용적인 부분들 위주로 집중해서 들었다.  
오늘은 git을 local에서 다루는 법만 배웠는데, 다음주에는 아마 github와 연동하여 다루는 법을 배울 듯하다.  

특강을 다 듣고 피어세션을 마친 후에 시간이 생각보다 많이 남아서 지난주 심화 과제를 모두 풀고, 내일 들을 예정이었던 강의를 하나 미리 들었다.  
심화 과제는 adversarial model에 대한 코드를 완성하는 것이었다. 지난주 오피스 아워 내용을 떠올리면서 풀어보니 그래도 구조가 많이 이해가 되었다.  
모델이 어떤 과정을 거쳐 학습하는지는 이해가 되었는데, 그 기반이 되는 수학적 원리는 아직 완전히 소화하지 못했다.  

과제 해결 후에 들은 강의에서는 collaborative filtering을 이용한 평점 예측에 대해 배웠다.  
유저 U의 아이템 I에 대한 평가를 예측하기 위해, 다른 유저들과 아이템에 대한 정보들로 유사도를 계산하는 방식이다.  
유저들간의 유사성을 바탕으로 하는 UBCF와 아이템들간의 유사성을 바탕으로 하는 IBCF로 크게 나뉜다.  
유사도 측정법에는 Cosine, Pearson, Jaccard 등의 기법이 있고, 이런 유사도를 바탕으로 가장 가까운 K개의 자료만을 활용하는 기법을 K-NN CF라 한다.  
K개의 자료들로 평점을 예측할 때, 단순히 평균을 낼 수도 있겠지만 유사도를 이용해 가중합을 할 수도 있고, 평점 대신 각 유저들의 평균 평점에 대한 편차를 사용할 수도 있다.  

지난주에 비해 전반적인 난이도가 내려갔다는 느낌이 드는데, 이렇게 여유가 생긴 만큼 스터디와 같은 추가 공부에 더 시간을 투자해야겠다.  

>  오늘의 질문 횟수: 1  
>  오늘의 답변 횟수: 1  

+ ##### 키워드: Git, CF, Similarity measure

Day 18 (11/29)
---
오늘은 Model-based Collaborative Filtering(MBCF)에 대해 배웠다.  
어제 배운 UBCF, IBCF 등의 NBCF가 유저-아이템 행렬만을 활용한다면, MBCF는 유저-아이템 관계를 k개의 특성으로 패턴화할 수 있다고 가정하고 이 패턴을 찾는다.  
NBCF에 비해 서빙 속도가 빠르고, sparsity 문제와 scalability 문제를 개선했다는 등의 장점이 있다.  

기본적인 MBCF로 Singular Value Decomposition(SVD)이 있다. 본래는 선형대수학에서 사용되는 개념이라 한다.  
SVD는 유저 행렬 U, 아이템 행렬 V, 평가 행렬 R에 대해 R = USV를 만족하는 행렬 S를 찾는 것이다.  
다만 이 방법은 R 행렬에 결측치가 없어야 하기에 0이나 평균으로 결측치를 채워주는 Imputation이 필요하다.  
하지만 이 과정에서 computation cost, data 왜곡, overfitting 등의 문제가 생기기에 SVD의 원리만 차용한 Matrix Factorization(MF)이 고안되었다.  

MF는 각 유저를 k개의 feature로 나타낸 행렬 P, 각 아이템을 k개의 feature로 나타낸 행렬 Q를 활용한다.  
유저 u가 아이템 i에 대해 내린 평가 r_u,i를 P_u와 Q_i의 내적을 이용해 추론하고, 실제 평가와 추론값 사이의 차이를 줄이는 것이 목표다.  
이 기본개념에서 목적식에 L2-norm regularization 항을 추가하고, bias를 추가하고, 평가에 대한 confidence를 부여하고, 평가한 시각을 고려하는 등의 변형이 가능하다.  
이렇게 정의된 목적식에 대한 gradient를 구할 때, 단순히 SGD를 활용할 수도 있겠지만 Alternative Least Square(ALS)를 사용하는 것이 가능하다.  
ALS는 P와 Q의 gradient를 계산할 때 하나를 상수로 놓고 나머지에 대한 gradient를 계산하는 방식이다.  
MF에서는 ALS의 optima와 SGD의 optima가 같기에 이를 사용할 수 있다고 한다.  

만약 평점이 아니라 랭킹을 예측하고 싶다면 Bayesian Personalized Ranking(BPR)을 활용할 수 있다.  
이름처럼 Bayesian 통계학을 이용한 방식이다. 주어진 유저 선호 정보에 대한 파라미터의 확률(사후 확률)을 최대화하는 것이 목표이나, 이는 계산할 수 없는 값이다.  
그렇기에 주어진 파라미터에 대한 유저 선호 정보의 확률(가능도)와 파라미터에 대한 사전 정보(사전 확률)의 곱을 최대화하여 간접적으로 사후 확률을 최대화한다.  
이때 사전 확률은 정규 분포를 따른다고 가정한다.  
여기서도 SGD를 적용할 수 있지만, bootstrap 기반의 SGD를 활용하는 것이 더 좋다고 한다.  

강의를 다 들은 후 과제를 마치고, 멘토링 시간을 가졌다.  
처음 멘토링을 할 때는 어떤 질문을 해야 할지 몰라서 시간을 많이 허비했는데, 회차가 거듭될수록 내가 어떤 이야기를 들을 수 있을지 알게 되어 생산성이 좋아졌다.  
오늘은 내가 구현했던 basic model 프로젝트에 대한 코멘트로 시작했다.  
깃헙을 활용한 협업의 흐름에 대해 소개하시고, 변수명에 대한 코딩 컨벤션과 직관적인 변수명에 대해 강조하셨다.  
가급적 상수의 활용을 피하고, 의미 있거나 반복되는 단위들을 하나의 함수로 모으는 게 가독성이 좋다는 조언도 해 주셨다.  
PyTorch Lightning을 사용하면 좀 더 군더더기 없는 코드를 짤 수 있을 거라고도 하셨다.  

코드 리뷰 후에는 포트폴리오나 이력서를 어떤 식으로 쓰시는지 여쭤봤다.  
주로 깃허브에는 자신이 한 프로젝트의 소스 코드를 올려두고, 이력서 등에는 프로젝트를 논문의 흐름처럼 요약해서 적는 느낌이었다.  
시간 관계상 못한 질문도 있었는데, 나머지는 다음주에 다시 질문해야겠다.  

>  오늘의 질문 횟수: 2  
>  오늘의 답변 횟수: 3  

+ ##### 키워드: MBCF, MF, ALS, BPR, Code Review

Day 19 (11/30)
---
오늘은 추천 시스템에서 활용되는 여러 방법론들을 배웠다.  
가장 먼저 다룬 것은 Item2Vec 모델인데, 이 모델은 Word2Vec 모델의 SGNS 방법을 차용한 것이다.  
각 아이템들을 단어로, 한 유저가 소비한 아이템들을 하나의 문장으로 간주해 적용한 것이다.  
Item2Vec은 두 아이템을 입력으로 받아, 한 유저가 소비한 집합에 함께 속하면 1, 아니면 0을 반환하도록 훈련된다.  
이를 통해 비슷한 아이템들이 서로 비슷한 벡터를 갖도록 하는 것이 목표다.  

이렇게 학습을 통해 아이템을 잘 벡터화했다면 추천을 위해 특정 유저 벡터 또는 아이템 벡터와 가장 유사한 벡터들을 찾아야한다.  
이때 Brute Force로 K-NN을 찾는 것은 너무 비효율적이기에 정확도를 약간 희생하여 속도를 크게 높이는 여러 ANN 방법들이 제안되었다.  
대표적인 ANN에는 ANNOY, HNSW, IVF, Product Quantization 등이 있다.  

추천 문제에 대해 딥러닝 모델을 가장 먼저 도입한 것은 NCF이다.  
MF와 비슷한 방식이지만, 비선형 활성함수를 사용함으로써 표현력의 한계를 극복하려 한 모델이다.  
유저와 아이템을 각각 one-hot encoding 한 후 embedding layer를 통해 2개의 embedded vector로 만든다.  
2개의 embedded vector를 concatenation 하여 MLP 형태의 Neural CF layer에 통과시키면 유저와 아이템의 관련도 값을 얻는다.  

이 외에도 2단계 추천 시스템을 처음으로 활용하고, 도메인에 대한 지식을 바탕으로 여러 features를 풍부하게 활용한 YouTube Recommendation, 유저-아이템 행렬을 AutoEncoder 방식으로 활용한 AutoRec, CDAE 등을 배웠다.  

RecSys 강의를 듣다보니 CV나 NLP에 비해 도메인에 대한 배경지식이 굉장히 중요하다는 느낌을 받았다.  
피어세션 때 이야기를 나눠보니 다른 조원들도 이에 공감하는 것 같았다.  
그리고 실시간으로 빠른 서빙 속도를 필요로 하기에 모델 구조가 단순한 편이지만, 오히려 단순한 구조로 높은 성능을 발휘하기 위해 딥러닝 외에도 다양한 아이디어가 활용되는 것 같다.  

>  오늘의 질문 횟수: 0  
>  오늘의 답변 횟수: 0  

+ ##### 키워드: Item2Vec, ANN, NCF, AutoRec
