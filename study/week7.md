Week 7 (12/18 ~ 12/22)
===
>  ##### 주간 요약
>  첫 프로젝트 대회를 8등으로 마무리했다.  
>  결과는 아쉬웠지만 소통을 통해 유대감을 잘 쌓아왔기에 긍정적으로 마무리했다.  
>  창의적으로 다양한 시도를 해 본 것은 좋았지만, 적절한 모델 선정 등 효과적인 접근에 대한 능력이 부족했다.  

Day 31 (12/18)
---
오늘은 프로젝트를 위해 앙상블 함수를 구현했다.  
베이스라인 코드로 제공된 앙상블 기법만으로는 부족한 감이 있어서 새로운 기법을 활용해서 함수를 만들어봤다.  

다른 조원들이 좋은 결과를 낸 모델들이 있어서 해당 모델들을 내 기법으로 앙상블 했더니 결과가 조금 더 개선되었다.  
피어세션 때 이에 대해 얘기를 나눠봤는데, 일단 나는 앙상블 기법을 발전시키는 방향으로 더 시도해보고자 한다.  

앙상블 기법을 어떻게 구현했는지, 수식을 어떻게 활용했는지 등등 적을 만한 것들이 좀 더 있는데, 팀 프로젝트 경쟁이다보니 유출이 될 수 있을 듯해 생략했다.  
컨디션이 아직 완전히 회복되지 않았다는 문제가 남아있기도 해서, 오늘은 짧게 적고 좀 더 쉬어야겠다.  

+ ##### 키워드: 앙상블 기법 구현

Day 32 (12/19)
---
오늘은 앙상블 기법을 바꿔서 어제보다 성적을 조금 더 향상시켰다.  
등수는 전체 8등 중 3등으로 유지 중인데, 평가 수치인 RMSE를 어제보다 조금 더 줄였다.  
어제와 마찬가지로 조원들이 각자 모델을 조금씩 더 발전시켜오고, 나는 앙상블에 대해 더 고민해보기로 했다.  
슬슬 앙상블로 성능을 개선하는 데에는 한계가 있는 듯해서 기본 모델 성능의 향상이 필요한 시점인 것 같다.  

오피스아워에서는 온라인 테스트에 대한 내용을 다뤘다.  
실험군을 어떻게 나눌 것인가, 개선할 지표와 가드레일을 무엇으로 설정할 것인가, 그룹을 잘 나눴는지 어떻게 확인할 것인가 등등에 대한 얘기를 들었다.  

오피스아워 이후 멘토링에서는 프로젝트에 대한 조언들을 들었다.  
어떤 시도들을 해 볼 수 있을지, 실험은 어떤 순서로 해 봐야 할지 등을 얘기해주셨다.  

+ ##### 키워드: 온라인 테스트

Day 33 (12/20)
---
'simple is the best'라는 격언을 되새긴 날이었다.  
그동안 여러 앙상블 기법을 고안해보면서 테스트를 해 왔는데, 오히려 단순하게 결과값을 평균한 것이 제일 결과가 좋았다.  
그래서 다른 앙상블 기법을 적용해 볼 필요성이 좀 떨어지기도 했고, 현재 모델 결과들로는 앙상블로 성능을 더 높이기 어려워 보여서 하이퍼 파라미터 튜닝을 시작했다.  

튜닝을 하다 보니 유독 batch size에 valid loss가 크게 영향을 받았다.  
그래서 이에 대해 검색해봤는데, batch size가 작아질수록 loss의 분산이 커지고 다양한 데이터를 학습해서 regularization이 잘 되는 장점이 있다고 한다.  
대신 step이 많아지기 때문에 local optima에 빠지기 쉬운 단점이 있다고 한다.  
내가 튜닝을 해봤을 때는 batch size를 줄이면 valid loss가 계속 줄어들기만 했는데, 어쩌면 이번 대회의 데이터에 대해 global optima와 local optima가 비슷한 게 아닐까 싶기도 하다.  
그런데 이와는 별개로 valid dataset의 batch size가 줄어들어서 valid loss가 줄어드는 게 아닐까 싶은 생각도 들었다.  
각 예측의 error가 똑같아도 100개씩 묶어서 RMSE를 구한 후 평균을 구한 것과, 10000개씩 묶어서 RMSE를 구한 후 평균을 구한 것의 결과값이 다르기 때문이다.  
현재 베이스라인 코드에서는 batch_size 파라미터를 조정하면 train dataset과 valid dataset의 batch size가 동시에 조정된다.  
그래서 train dataset의 batch size를 고정하고 valid dataset만 바꿔봤는데, valid loss가 같게 나왔다.  
이를 보면 batch size를 줄이는 것이 모델의 예측 성능 자체를 높여준 게 맞는 듯하다.  

valid dataset 외에 test dataset에 대해서도 확인해보고 싶었는데, 오늘의 리더보드 제출 횟수를 다 써서 확인을 못 해 봤다.  
피어세션 때 이에 대해 회의했는데 일단 하이퍼 파라미터 튜닝을 더 해 보고 내일 결과를 확인하기로 했다.  
그 외에 책의 summary 정보를 읽어서 bert를 이용해 embedding으로 변환 후 예측에 활용하는 접근도 진행 중인데, 팀에서 다른 조원 분들이 맡아주시기로 해서 마찬가지로 내일 결과를 보기로 했다.  

이론 공부를 할 때와 달리 프로젝트를 시작하니 왠지 AI와 개발자 취업 등에 대해 회의감이 많이 들었다.  
이전에는 적절한 논리를 통해 모델을 설계하고 튜닝하면 성능이 잘 나올 거라는 믿음이 있었는데, 막상 프로젝트를 시작하니 단순한 접근들이 더 성과가 좋아서 그런 것 같다.  
다른 조원 분도 비슷한 고민을 하고 계신다고 해서 '나만 이렇게 생각하는 게 아니구나' 라는 생각이 들었다.  
내일이면 프로젝트도 마무리 되니까 조원 분들께 폐를 끼치지 않도록 조금만 더 힘내서 잘 마무리해야겠다.  

+ ##### 키워드: 하이퍼 파라미터 튜닝, batch size, 진로

Day 34 (12/21)
---
어제에 이어서 하이퍼 파라미터 튜닝을 마저 하고, 최종 결과를 제출했다.  
리더보드 순위는 아쉽게도 8등으로 마무리 했고, private score는 아직 비공개라 내일 확인할 예정이다.  
그동안 다양한 방법을 시도해보려 했던 것에 비해 결과는 별로였고, 단순히 모델을 이것저것 튜닝해 보면서 결과를 낸 게 생각보다 성과가 좋았다.  
그래도 '이런 방법들은 효과가 잘 안 나오는구나' 하는 것들도 나름의 성과가 아닐까 싶다.  
베이스라인 코드에 있는 모델들 외에도 library 같은 걸 활용해서 여러 모델을 테스트 해 보면 더 좋지 않았을까 하는 생각도 든다.  

성과와는 별개로 프로젝트 대회가 끝나서 마음이 좀 가벼워졌다.  
아쉬운 부분도 있지만 내가 배운 것들도 있기에 만족하기로 했다.  

최종 제출을 마치고 조원들과 랩업 리포트를 어느 정도 작성한 후에 수다를 떨면서 시간을 보냈다.  
다 같이 줌 배경화면을 바꾸고 놀면서 사진 찍고, 프로필 사진도 바꾸고 하면서 재밌게 놀았다.  
2주간 힘들게 보내고 나서 맞이하는 평화라서 더 좋았던 것 같다.  
한편으로는 잠깐의 휴식 뒤에 또 새로운 프로젝트를 하면서 기운을 뺄 생각을 하니 막막하기도 했다.  
총 22주의 교육 과정 중에 7주차가 마무리 되어가는데, 아직 많이 남았구나 싶기도 하면서 벌써 7주차나 됐구나 싶은 생각도 든다.  
진로 고민, 멘탈 관리, 그 외에 개인적인 일들로 요즘 생각이 많아지는데, 모든 문제를 잘 이겨내고 싶다.  

+ ##### 키워드: 프로젝트 대회 종료

Day 35 (12/22)
---
프로젝트 마무리 후 쉬어가는 느낌의 하루였다.  
오전에는 취업 특강을 듣고, 오후에는 프로젝트 랩업 리포트 작성 후 다른 조들의 솔루션 발표를 들으며 마무리했다.  

취업 특강에서는 커리어를 시작하기 위한 준비 과정을 위주로 말씀해주셨다.  
우선 나에 대해 파악하고, 이를 바탕으로 여러 경험들을 일찍, 다양하게 겪어보라고 하셨다.  
그 과정에서 여러 기회들을 만나게 되고, 또 경험을 통해 그 기회들 중 나에게 맞는 것을 솎아낼 수 있게 된다고 한다.  
이때 면접 등에서 경험을 어필하려면, 경험의 다양성보다는 특출난 하나의 성과를 강조하는 것에 집중하라고도 조언하셨다.  
특히, 100을 가지고 있음에도 80을 가진 것처럼 드러내는 사람들이 있는데, 오히려 120을 가진 것처럼 자신을 드러내라고 하신 말씀이 기억에 남는다.  
나는 자신을 드러내고 어필하는 것이 익숙하지 않아서 말씀하신 것처럼 80을 드러내는 케이스에 완전히 공감했다.  
사실 120을 드러내는 것이 유리한 걸 알면서도 80을 드러내는 내 성격 때문에 나는 취업보다는 학문 계열이 더 어울리지 않을까? 라는 생각도 했었다.  
그런데 나와 비슷한 케이스가 생각보다 많다는 이야기를 들으니 조금은 위로가 되었다.  

특강 이후 오후엔 랩업 리포트를 쓰며 프로젝트 진행 과정을 돌아보고, 다른 캠퍼 분들을 만나 이번 프로젝트에 대해 이야기를 나눴다.  
사실 결과가 좋지 않아서 내가 시도했던 여러 접근들이나 아이디어들이 부정당한 느낌이었는데, 다른 조의 캠퍼 분들이 격려를 많이 해 주셨다.  
자신들의 조에서는 앙상블을 건드려 볼 생각은 못 했는데 새로운 수식을 고안해서 앙상블을 시도한 게 창의적이었다는 반응도 있었고,  
batch size를 줄이면 분명 valid loss가 계속 줄어드는데 리더보드 결과는 안 좋은 이유를 몰랐는데 valid batch size가 RMSE에 영향을 미친다는 내 설명을 듣고 이해가 됐다는 분도 계셨다.  
어쩌면 성적이 좋지 않았던 사람에게 건네는 단순한 위로일 수도 있겠지만, 그럼에도 내가 한 노력들이 모두 헛된 것은 아니겠구나 라는 생각을 들게 해 줬다.  

다른 조의 발표를 들어보니 우리 조와 접근 과정이 좀 달랐다는 것이 느껴졌다.  
우리는 베이스라인 코드에서 구현된 모델들을 어떻게 개선해서 활용할지에 집중했던 반면,  
다른 조들은 catboost와 같은 다른 모델들도 다양하게 활용해보며 적합한 모델을 선정하는 과정을 먼저 진행했다.  
그리고 1등 조에서는 데이터 전처리를 한 후 feature와 평점의 상관관계를 ANOVA 검정으로 확인하고 유의한 feature만을 활용했다는 점이 인상 깊었다.  
나도 feature와 평점의 상관관계를 파악하면 좋겠다는 생각은 들었지만 크게 효과적이지 않을 거라 생각하고 실천에 옮기진 않았었다.  
게다가 분석을 한다고 하더라도 어떻게 검정을 해야 할지는 잘 몰랐는데, 이런 점에서 구체적으로 ANOVA를 활용하고 이를 통해 실제적으로 좋은 성과를 낸 것이 굉장히 놀라웠다.  
이후에 마스터님께서 피드백을 하시며 ANOVA로 feature를 검정하는 것이 좋은 접근일 수도 있지만, 항상 유의미한 결과를 낳는 것은 아니라는 주의도 주셨다.  
ANOVA 외에도 범주화를 할 때 미성년자의 age는 3년 단위로 묶고, 성인은 10년 단위로 묶는 등 나는 사소하게 생각하고 넘어갔던 부분들을 하나하나 꼼꼼하게 다룬 것을 보고 배웠다.  

이번 프로젝트 대회에서 순위만 놓고 보면 굉장히 아쉬운 결과를 거뒀지만, 이런 결과임에도 팀원들과는 웃고 떠들면서 이전보다 가까워졌다.  
어느 팀이나 실패는 겪을 수 있지만, 실패 후에 서로를 질책하지 않고 웃어 넘김으로써 팀워크를 다지고 다음에도 도전할 기회를 만들 수 있다고 생각한다.  
이런 점에서 우리 조는 최소한 소통을 통해 유대감을 쌓는 것에는 충분히 성공하지 않았나 싶다.  

+ ##### 키워드: 취업 특강, 팀워크크
